### 1. Her yaml dosyası 4 ana bileşenden oluşur.

``` 
apiVersion: hangi api versionuyla tanımlanacak.
kind      : hangi tür obje oluşturulacak
metadata  : unig bilgileri tanımlarız.İsim gibi
spec      : objenin özelliklerini belirleme
``` 

- objectbasetemplate.yaml
``` 
apiVersion: v1
kind: Pod
metadata:
  name: firstpod
  labels:
    app: front-end
spec:
  containers:
  - name: nginx 
    image: nginx:latest
    ports:
    - containerPort: 80
``` 

``` 
kubectl apply -f pod1.yaml
``` 

``` 
kubectl describe pods firstpod
``` 

### 2. Pod Yaşam döngüsü

- Always : Container içindeki uygulama bir şekilde kapanırsa her zamana tekrardan çalışması komutu.
- On-failure: hata alıp kapanırsa yeniiden çalışır
- Never : Hiç bir zaman başlamaz

``` 
Pending          : Pod ile ilgili bilgiler kaydedildi ancak oluşturulamadı.
Creating         : Kube scheduler üretim için node ayarlar uygun node bulamamış ise yaratma olmaz
İmagePullBackOff : Kubelet oluşturamayınca olan hata
Running          : Kubelet container yapma süreci
Succeeded        : Başarılı şekilde başlamış
Failed           : Başarılı olmamışsa
CrashLoopBackOff : Container sık sık kapanıuorsa container çalışma durumu bunu gösterir.
``` 

### 3. Çoklu Container
- Nginx imajedan oluşan bir web sayfası oluşturulacak
- 2. container web ile ilgili bilgilerin bulunduğu github deposundan bilgileri alacak ve volume kaydedecek
- Nginx de aynı volume bağlı olduğu için burdaki bilgileri okuyarak web i güncelleyecek 

-podmulticontainer.yaml
``` 
apiVersion: v1
kind: Pod
metadata:
  name: multicontainer
spec:
  containers:
  - name: webcontainer
    image: nginx
    ports:
      - containerPort: 80
    volumeMounts:
    - name: sharedvolume
      mountPath: /usr/share/nginx/html
  - name: sidecarcontainer
    image: busybox
    command: ["/bin/sh"]
    args: ["-c", "while true; do wget -O /var/log/index.html https://raw.githubusercontent.com/ozgurozturknet/hello-world/master/index.html; sleep 15; done"]
    volumeMounts:
    - name: sharedvolume
      mountPath: /var/log
  volumes:
  - name: sharedvolume
    emptyDir: {}

``` 

```
kubectl apply -f podmulticontainer.yaml
```

```
kubectl get pods
```

```
kubectl port-forward pod/multicontainer 8080:80
```


### 4. Init Container

- Bir container çalışmadan diğer container çalışmaz.

- podinitcontainer.yaml
```
apiVersion: v1
kind: Pod
metadata:
  name: initcontainerpod
spec:
  containers:
  - name: appcontainer
    image: busybox
    command: ['sh', '-c', 'echo The app is running! && sleep 3600']
  initContainers:
  - name: initcontainer
    image: busybox
    command: ['sh', '-c', "until nslookup myservice; do echo waiting for myservice; sleep 2; done"]
    
```

```
kubectl apply -f podinitcontainer.yaml
```

### 5. Label ve Selector

- Etiketler ve etiket seçimleri ile oluşturdugumuz objelere anlayacağımız bilgiler ekliyoruz.
- Etiketler obje oluşturuken kurulur veya obje oluşturulduktan sonra.
- Kubernets de bağlantılar etiketler sayesinde olur

```
apiVersion: v1
kind: Pod
metadata:
  name: pod1
  labels:
    app: firstapp
    tier: frontend
    mycluster.local/team: team1
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod2
  labels:
    app: firstapp
    tier: frontend
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod3
  labels:
    app: firstapp
    tier: backend
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod4
  labels:
    app: firstapp
    tier: backend
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod5
  labels:
    app: secondapp
    tier: frontend
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod6
  labels:
    app: secondapp
    tier: frontend
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod7
  labels:
    app: secondapp
    tier: backend
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod8
  labels:
    app: secondapp
    tier: backend
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod9
  labels:
    team: team1
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod10
  labels:
    team: team2
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: pod11
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
  nodeSelector:
    hddtype: ssd
```

- app isimli etiketler 
```
kubectl get pods -l “app” --show-labels
```

- app etiketi belirliyorum
```
kubectl get pods -l “app=firstapp” --show-labels
```

- birden fazla etiket giriyorum bunu virgül ile yapıyorum
```
kubectl get pods -l “app=firstapp, tier=frontend” –show-labels
```

- birden fazla etiket giriyorum
```
kubectl get pods -l “app=firstapp, tier!=frontend” –show-labels
```

- farklı bir biçimde etiket tanımlama
```
kubectl get pods -l ‘app in (firstapp)’ --show-labels
kubectl get pods -l ‘app in (firstapp,secondapp)’ --show-labels
```

-app firstapp olarak antanmamışları listele
```
kubectl get pods -l ‘app notin (firstapp)’ --show-labels
```

- app anahtarına sahip olcak ve firstapp olarak atanmamaışları getir
```
kubectl get pods -l ‘app, app notin (firstapp)’ --show-labels
```

- app anahtrarına sahip olmayanları bul
```
kubectl get pods -l ‘!app’ --show-labels
```

- app anahtarı atanmış tier değeri frontend olmayanları bulmasını istiyorouz
```
kubectl get pods -l “app in (firstapp), tier notin(frontend)” --show-labels
```

- Sonradan etiket ekleme

```
kubectl get pods --show-labels
kubectl label pods pod9 app=thirdapp
```

- Etiket silme
```
kubectl label pods pod9 app-
```

- Etiket güncelleme
```
kubectl label --overwrite pods pod9 team=team3
kubectl get pods --show-labels
```

- Objeler arasında ilişki kurmak
```
kubectl label nodes minikube hddtype=ssd
```

### 6. Annotation

- Objeye onu tanımlayan fakat label olarak eklememizin sakıncalı olacağı bilgileri annotation "açıklama" olarak ekleriz.

- Prefix "örnek" kısmı opsiyoneldir. Zorunlu değildir.

- Alfanumerik bir karakterle ([a-z0-9 A-Z]) başlamalı ve bitmelidir.

- Tire (-), alt çizgi (_), noktalar (.) ve arasında alfanumerik değerler içerebilir.

- Değer alanında bu kurallar geçerli değildir. Alfanümerik olmayan karakter de alabilir.

- podannotation.yaml
```
apiVersion: v1
kind: Pod
metadata:
  name: annotationpod
  annotations:
    owner: "Ozgur OZTURK"
    notification-email: "admin@k8sfundamentals.com"
    releasedate: "01.01.2021"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
spec:
  containers:
  - name: annotationcontainer
    image: nginx
    ports:
    - containerPort: 80

```    

```
kubectl apply -f podannotation.yaml
```

```
kubectl describe pod annotationpod
```

- Ekleme
```
kubectl annotate pods annotationpod foo=bar
```

- Silme
```
kubectl annotate pods annotationpod foo-
```


### 7. Names Space

- 10 kişinin dosya paylaşacağı bir sistem nasıl kurarım.
- Namespaceler cluster kaynaklarını birden çok kullanıcı arasında bölmenin bir yoludur.
- Namespaceler adlar için bir kapsam sağlar. 
- Kaynak adlarının bir namespace içinde benzersiz olması gerekir. 
- Namespace birbirinin içine yerleştirilemez ve her Kubernetes kaynağı yalnızca bir namespace içinde olabilir.

```
kubectl get namespaces
```

- default         : Aksini belirtmediğimiz sürece objeler burda oluşturulur.
- kube-node-lease : Özel işlemleri içeren namespacedir.
- kube-public     : Kimliği doğrulanmamış olanlar dahil tüm kullanıcıların erişebileceği yerdir.
- kube-system     : Kubernets tarafından oluşturulan objelerin oluşturulduğu namespacdir.


- Yeni bir name space oluşturma
```
kubectl create namespace app1
```

- Namespceleri sıralama
```
kubectl get namespace
```

- podnamespace.yaml
```
apiVersion: v1
kind: Namespace
metadata:
  name: development
---
apiVersion: v1
kind: Pod
metadata:
  namespace: development
  name: namespacepod
spec:
  containers:
  - name: namespacecontainer
    image: nginx:latest
    ports:
    - containerPort: 80
```

```
kubectl get namespace
```

```
kubectl create namespace app1
```

```
kubectl apply -f podnamespace.yaml
```

```
kubectl get pods -n development
```

İletişim kuracağımız obje ile iletişim kurmak istiyorsak namespace belirtmeliyiz.
```
kubectl exec -it namespacedpod -n development -- /bin/sh
```


Varsıyalan değerini değiştirmek istiyorsak
```
kubectl config set-ccontext --current --namespce=development
kubectl get pods
```

namespace silme
```
kubectl delete namespces development 
```

### 8. Deployment
- Uygulamamızı imaj haline getirir ve pod olarak deploy ederiz.
- Kubernets de podlar genellikle singel olarak yaratılmaz.
- Podları yöneten üst seviye bir obje yaratırırz ve podlar bu objeler tarafından yaratılıp yönetilir.
- Bu üst seviye objelerden biride "deployment" dır.
- Bir Deployment'da istenen durumu tanımlarsınız ve Deployment Controller, mevcut durumu istenilen durumla karşılaştırıp gerekli aksiyonları alır.


```
kubectl create deployment firstdeployment --image=nginx:latest --replicas=2
```

```
kubectl get deployment
```

-deployment güncelleme
```
kubectl set image deployment/firstdeployment nginx=httpd 
```

-pod sayısını ayarlama
```
kubectl scale deployment firstdeployment --replicas=5
```

- deployment silme
```
kubectl delete deployments firstdeployment
```

- deployment.yaml version 1
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: firstdeployment
  labels:
    team: development
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
```

- matchLabels: Lable ile hangi imaje deploye edeceğini öğrenir.
- selector kısmında "frontend" ile bilgi veriyorum.
- template kısmında "frontend" ile bu pod bilgilerini kullan diyorum

- deployment.yaml version 2
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: firstdeployment  
  labels:
    team: development
spec:
  replicas: 3            
  selector:
    matchLabels:
      app: frontend
  template:              
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

```
kubectl get pods
```

### 9. Replicaset

- Deployment replicaset oluşturur replicaset deployment da belirtilen özelliklere göre pod oluşturur.
- Bir ReplicaSet'in amacı, herhangi bir zamanda çalışan kararlı bir replika Pod setini sürdürmektir. 
- Bu nedenle, genellikle belirli sayıda özdeş Pod'un kullanılabilirliğini garanti etmek için kullanılır.

- rs.yaml
```
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: firstrs
  labels:
    app: rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rs
  template:
    metadata:
      labels:
        app: rs
    spec:
      containers:
      - name: nginx
        image: nginx
```


```
kubectl apply -f rs.yaml
```

```
kubectl get replicaset
```

```
kubectl delete rs firstrs
```


### 10. Rollout - Recreat
- RollbackRollout ve Rollback kavramları, deploment'ın güncellenmesi sırasında devreye girer, anlam kazanır.
- YAML ile deployment tanımı yapılırken 2 tip strategy seçilir:


### 10.1. Recreat
- recreat: Bu deploymenta bir değişiklik yaparsam öncelikle tüm mevcut kodları sil ve bu işlem tamamlandıktan sonra yeni podları 
  oluşturur.
- Bu yöntem daha çok hardcore migration yapıldığında kullanılır.
- Uygulamanın yeni versionuyla eski versionunun birlikte çalışması sakıncalı ise bu yöntem seçilir.

- deployrecreate.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rcdeployment
  labels:
    team: development
spec:
  replicas: 3
  selector:
    matchLabels:
      app: recreate
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: recreate
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
```

```
kubectl apply -f deployrecreate.yaml --record
```

```
kubectl set image deployment deployrecreate.yaml nginx=httpd:alpine --record=ture 
```

```
kubectl set image deployment deployrecreate.yaml nginx=httpd:alpine --record=ture 
```

### 10.2. RollingUpdate

- RollingUpdate: Ben bir değişiklik yaptığım zaman tüm kodları silip yenisini oluşturma bunun yerine bu işi aşamalı olarak yap. 

- deployrolling.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rolldeployment
  labels:
    team: development
spec:
  replicas: 10
  selector:
    matchLabels:
      app: rolling
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 2
      maxSurge: 2
  template:
    metadata:
      labels:
        app: rolling
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
```

```
kubectl apply -f deployrolling.yaml --record
```

- record yapılan değişikleri kayderder
```
kubectl set image deployment rolldeployment nginx=httpd:alpine --record=ture 
```

```
kubectl rollout history deployment rolldeployment
```

istediğim aralıktaki değişiklikleri göster
```
kubectl rollout history deployment rolldeployment --revision=2 
```

istediğim hale geri dönme
```
kubectl rollout undo deployment rolldeployment --to-revision=1
```

Yapılan işlemi durdurur.
```
kubectl rollout pause deployment status deployment rolldeployment -w
```

### 11. Kubernetes Ağ Kuralları

Kubernetes ağ kuralları
- Kubernetes kurulumda pod'lara ip dağıtılması için bir ip adres aralığı ya da kubernetes terminolojisinde bilinen adıyla --pod-network-cidr belirlenir.
- Kubernetes'de her pod bu "cidr" bloğundan atanacak bir eşsiz ip adresine sahip olur.
- Aynı cluster içerisindeki tüm podlar varsayılan olarak birbirleriyle herhangi bir kısıtlama olmadan ve NAT yani network address translation olmadan haberleşebilirler.
- Calico gibi hizmetler haberleşmeyi sağlayan hizmet türleridir.
- "Dış Dünya" Container'lar ile Service objesiyle haberleşir.

### 12. Service
- Backend ve Fronted adlı iki tür yazılıma sahibiz ve bunlar her biri 3 er tane pods ile kubernets de deploy edilmektedir.
- Backend ve Fronted toplam 6 podun bir biryle iletişimi nasıl kuracağını açıklayacağız.

- Çözüm olarak Service hizmetlerini 4 farklı şekilde kulannabiliriz.

### 12.1 ClusterIP (Container'lar Arası)
- Bir ClusterIP service'i yaratıp, label'lar sayesinde podlarla ilişkilendirebilir. 
- Bu obje yaratıldığında, Cluster içerisindeki tüm podların çözebileceği unique bir DNS adresi olur. 
- Ayrıca, her k8s kurulumunda sanal bir IP range'e sahip olur. (Ör: 10.0.100.0/16)
- ClusterIP service objesi yaratıldığı zaman, bu objeye bu IP aralığından bir IP atanır ve ismiyle bu IP adresi Cluster'ın DNS mekanizmasına kaydedilir. 
- Bu IP adresi Virtual (Sanal) bir IP adresidir. 
- Kube-proxy tarafından tüm node'lardaki IP Table'a bu IP adresi eklenir. 
- Bu IP adresine gelen her trafik Round Troppin algoritmasıyla Pod'lara yönlendirilir. 
- Böylece; Frontend node'larına bu IP adresi tanımlanarak (ismine de backend denirse), backend’e erişim için bu IP adresinin kullanılması sağlanabilir. 
- (Selector = app:backend) Tek tek her defasında Frontend podlarına Backend podlarının IP adresleri eklenmek zorunda kalınmaz.

### 12.2 NodePort Service (Dış Dünya -> Container) 
- Bu service tipi, Cluster dışından gelen bağlantıları çözmek için kullanılır. 
- NodePort key’i kullanılır.
- Label selector aracılığıyla ilişkilendirir.

### 12.3 LoadBalancer Service (Cloud Service’leri İçin) 
- Bu service tipi, sadece Agent K8s, Google K8s Engine gibi yerlerde kullanılır.

### 12.4 ExternalName Service

### 12.5 Service Uygulama

deploy.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  labels:
    team: development
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: ozgurozturknet/k8s:latest
        ports:
        - containerPort: 80
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  labels:
    team: development
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: ozgurozturknet/k8s:backend
        ports:
        - containerPort: 5000
```

```
kubectl apply -f deploy.yaml
```

```
kubectl get pods
```

- serviceClusterIP.yaml
```
apiVersion: v1
kind: Service
metadata:
  name: backend
spec:
  type: ClusterIP
  selector:
    app: backend
  ports:
    - protocol: TCP
      port: 5000
      targetPort: 5000
```

```
kubectl apply -f serviceClusterIP.yaml
```

```
kubectl get service
```

- serviceLoadBalancer.yaml
```
apiVersion: v1
kind: Service
metadata:
  name: frontendlb
spec:
  type: LoadBalancer
  selector:
    app: frontend
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
```      

### 11.6 Uygulama 2

```  
kubectl expose deployment backend --type=ClusterIP --name=backend
```  

```
kubectl get service
```

```  
kubectl expose deployment backend --type=NodePort --name=backend
```  
```
kubectl get service
```

### 12. Endpoint Nedir?
- Nasıl deployment'lar aslında ReplicaSet oluşturdu ise, Service objeleri de arka planda birer Endpoint oluşturur. 
- Service'lere gelen isteklerin nereye yönleneceği Endpoint'ler ile belirlenir. 

```
kubectl get endpoints
```

### 13. Liveness Probe

- Liveness Probes Bazen container içerisinde çalışan bir uygulama, düzgün çalışmayabilir. 
- Uygulama çökmemiş, kapanmamış ama aynı zamanda işlevini tam yerine getirmiyorsa kubelet bunu tespit edemiyor. 
- Bir uygulama çalışıyor görünmesine rağmen, zombi olabilir. 
- Bu durumda bir container'ı yeniden başlatmak, hatalara rağmen uygulamayı kullanılabilir hale getirebilir. 
- Liveness; container'a bir request göndererek, TCP connection açarak veya container içerisinde bir komut çalıştırarak doğru çalışıp çalışmadığını anlamayı sağlar.
- Kubelet, bir container'ın ne zaman yeniden başlatılacağını belirlemek için liveness probe'ları kullanır.

- liveness.yaml
```
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-http
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/liveness
    args:
    - /server
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
        - name: Custom-Header
          value: Awesome
      initialDelaySeconds: 3
      periodSeconds: 3
---
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-exec
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/busybox
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5
      periodSeconds: 5
---
apiVersion: v1
kind: Pod
metadata:
  name: goproxy
  labels:
    app: goproxy
spec:
  containers:
  - name: goproxy
    image: k8s.gcr.io/goproxy:0.1
    ports:
    - containerPort: 8080
    livenessProbe:
      tcpSocket:
        port: 8080
      initialDelaySeconds: 15
      periodSeconds: 20
```

### 13. Readiness Probes

- Kubelet, bir containerin ne zaman trafiği kabul etmeye hazır olduğunu bilmek için readiness probeları kullanır. 
- Bir Pod, tüm containerlar hazır olduğunda hazır kabul edilir. 
- Readiness probe sayesinde bir Pod hazır olana kadar service arkasına eklenmez.

- Senaryo gereki 3 poda çalışan bir uygulamamız var ve bu uygulamayı yayınladığımız deployment dosyasında değişiklik yaptık.
- Uygulama tekrardan ayağa kalkacak ancak önce bazı dosyaları indirmesi geekiyor sonra yayına hazır olması gerekli
- İşte budurumu kontrol eden özelliğe readline probe demekteyiz.

- ProbesDeployment Güncelleme Senaryosu ve Readiness Probe 
```
Deployment güncellendi "v2 imaji".
Yeni imajla yeni bir pod (v2) oluşturuldu.
Yeni pod (v2) çalışmaya başladı.
readiness check mekanizması çalışmaya başladı. initialDelaySeconds kadar bekledi ardından ilk kontrolünü yaptı.
Kontrol sonucu olumlu olduğu anda pod (v2) service'e eklendi.
Bu noktada eski pod'un (v1) service ile bağlantısı kesildi.
Eski pod (v1) "eğer işlemesi gereken istekler varsa işlemeye devam etmesi için" henüz kapatılmadı.
Eski pod'un (v1) kendini düzgün kapatması için sistem sigterm sinyali gönderdi.
Pod (v1) üzerindeki işlemleri tamamladıktan sonra kendisi kapattı
```
terminationGracePeriodSconds: 30 Mevcut işlemler biter, 30 sn bekler ve kapanır.

readiness.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  labels:
    team: development
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: ozgurozturknet/k8s:blue
        ports:
        - containerPort: 80
        livenessProbe:
          httpGet:
            path: /healthcheck
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 80
          initialDelaySeconds: 20
          periodSeconds: 3
---
apiVersion: v1
kind: Service
metadata:
  name: frontend
spec:
  selector:
    app: frontend
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80

```

### 14. Resource Limits

- Pod'ların CPU ve Memory ayarlamalarını yönetmemiyi sağlar. 
- Aksi belirtilmedikçe k8s üzerinde çalıştığı makinenin CPU ve Memory'sini %100 kullanabilir. 
- Bu durum bir sorun oluşturabileceği için Pod'ların CPU ve Memory kullanamı sınırlandırılır.

- requestlimit.yaml
```
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: requestlimit
  name: requestlimit
spec:
  containers:
  - name: requestlimit
    image: ozgurozturknet/stress
    resources:
      requests:
        memory: "64M"
        cpu: "250m"
      limits:
        memory: "256M"
        cpu: "0.5"
```

### 15. Environment Variable

- Çalıştırdığımız ortama göre değişicek bilgileri container imajlarına gömmeyiz. 
- Onun yerine uygulamamızda bunlar çalıştırıldıklarında okunacak değişkenler olarak tanımlarız.

```
apiVersion: v1
kind: Pod
metadata:
  name: envpod
  labels:
    app: frontend
spec:
  containers:
  - name: envpod
    image: ozgurozturknet/env:latest
    ports:
    - containerPort: 80
    env:
      - name: USER
        value: "Ozgur"
      - name: database
        value: "testdb.example.com"
```
```
kubectl apply -f podeny.yaml
```
```
kubectl get po-w
```

### 15.1. Port-Forward (Local -> Pod)

- Local sunuculardan k8s cluster'ı içerisindeki objelere direkt ulaşabilmek için port-forward yapılabilir. 
- Bu objeyi test etmek için en iyi yöntemlerden biridir.

- kubectl port-forward <objectType>/<podName> <localMachinePort>:<podPort>

```
kubectl port-forward pod/envpod 8080:80
```
- curl 127.0.0.1:8080


### 16.Volume

- Container’ın dosyaları container varolduğu sürece bir dosya içerisinde tutulur. 
- Eğer container silinirse, bu dosyalarda birlikte silinir. 
- Bazı containerlarda bu dosyaların silinmemesi (tutulması) gerekebilir.  
- Ephemeral Volume'ler aynı pod içerisindeki tüm containerlara aynı anda bağlanabilir. 
- Diğer bir amaç ise aynı pod içerisindeki birden fazla container'ın ortak kullanabileceği bir alan yaratmaktır.
- Ephemeral Volume'lerde Pod silinirse tüm veriler kaybolur. 
- Fakat, container silinip tekrar yaratılırsa Pod'a bir şey olmadığı sürece veriler saklanır. İki tip Ephemeral Volume vardır:
- Ephemeral / emptyDir || Ephemeral / hostPath

### 16.1 
- Ephemeral / emptyDir: 
- VolumeemptyDir volume ilk olarak bir Pod bir node'a atandığında oluşturulur ve bu Pod o node'da çalıştığı sürece var olur. 
- Adından da anlaşılacağı gibi, "emptyDir" birimi başlangıçta boştur.
- Pod içindeki tüm containerlar, emptyDir volume'deki aynı dosyaları okuyabilir ve yazabilir, ancak bu birim her kapsayıcıda aynı veya 
  farklı yollara mount edilebilir.
- Bir Pod herhangi bir nedenle bir node'dan silindiğinde, emptyDir içindeki veriler de kalıcı olarak silinir.

- podvolumeemptydir.yaml
```
apiVersion: v1
kind: Pod
metadata:
  name: emptydir
spec:
  containers:
  - name: frontend
    image: ozgurozturknet/k8s:blue
    ports:
    - containerPort: 80
    livenessProbe:
      httpGet:
        path: /healthcheck
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 5
    volumeMounts:
    - name: cache-vol    # volume ile bağlantı sağlamak için.
      mountPath: /cache  # volume içerisindeki hangi dosya?
  - name: sidecar
    image: busybox
    command: ["/bin/sh"]
    args: ["-c", "sleep 3600"]
    volumeMounts:
    - name: cache-vol
      mountPath: /tmp/log   # volume içerisindeki hangi dosya?
  volumes:
  - name: cache-vol         # Önce volume'ü oluşturur sonra container'lara tanımlarız.
    emptyDir: {}

```

```
kubectl get pods
```

```
kubectl apply -f podvolumeemptydir.yaml
```

```
kubectl apply -f podvolumeemptydir.yaml -c fronted --bash
```

```
cd cache
touch picture1.jpg 
touch picture2.jpg
```

### 16.2 
- Ephemeral / hostPath 
- VolumeBir hostPath volume, worker node dosya sisteminden Pod'a bir dosya veya dizini bağlayabilme imkanı verir. 
- Çoğu Pod ihtiyaç duymaz, ancak bazı uygulamalar için güçlü bir kaçış kapısıdır. 
- Çok nadir durumlarda kullanılır, kullanılırken dikkat edilmelidir. 
- emptyDir’da volume klasörü pod içerisinde yaratılırken, hostPath’te volume klasörü worker node içerisinde yaratılır.

- Directory         –> Worker node üzerinde zaten var olan klasörler için kullanılır.
- DirectoryOrCreate –> Zaten var olan klasörler ya da bu klasör yoksa yaratılması için kullanılır.
- FileOrCreate      –> Klasör değil! Tek bir dosya için kullanılır. Yoksa yaratılır.

- podvolumehostpath.yaml
```
apiVersion: v1
kind: Pod
metadata:
  name: hostpath
spec:
  containers:
  - name: hostpathcontainer
    image: ozgurozturknet/k8s:blue
    ports:
    - containerPort: 80
    livenessProbe:
      httpGet:
        path: /healthcheck
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 5
    volumeMounts:
    - name: directory-vol
      mountPath: /dir1
    - name: dircreate-vol
      mountPath: /cache
    - name: file-vol
      mountPath: /cache/config.json       
  volumes:
  - name: directory-vol
    hostPath:
      path: /tmp
      type: Directory
  - name: dircreate-vol
    hostPath:
      path: /cache
      type: DirectoryOrCreate
  - name: file-vol
    hostPath:
      path: /cache/config.json
      type: FileOrCreate
```


```
kubectl apply -f podvolumehostpath.yaml
```

```
kubectl exec -it hostpath --bash
```


### 17. Srcret
- Hassas bilgileri (user, password gibi) saklamak için Environment Variables kullanılabilse de, bu yöntem ideal olmayabilir. 
- Secret objesi hassas bilgileri uygulamanın obje tanımlarının yapıldığı YAML dosyalarından ayırır ve ayrıca yönetilmesini sağlar. 
- Token, username, password gibi bilgileri secret ile saklamak her zaman daha güvenli ve esnektir.

### 17.1 Declarative Secret Oluşturma 

- Atanacak secret ile oluşturulacak pod'lar aynı namespace üzerinde olmalıdır. 
- 8 farklı tipte secret oluşturulabilir. Burada "Opaque"

- secret.yaml
```
apiVersion: v1
kind: Secret
metadata:
  name: mysecret
type: Opaque  
stringData:		# Hassas data'ları stringData altına yazıyoruz.
  db_server: db.example.com
  db_username: admin
  db_password: P@ssw0rd!
```

```
kubectl apply -f secrect.yaml
```

```
kubectl get secrects
```

### 17.2 Imperative Secret Oluşturma

```
kubectl create secret generic <secretName> --from-literal=db_server=db.example.com --from-literal=db_username=admin
```

```
kubectl create secret generic <secretName> --from-file=db_server=server.txt --from-file==db_posword.txt
```

### 17.3 Pod’dan Secret’ı Okuma
- Pod’dan Secret’ı OkumaOluşturulan Secret'ı Pod'a aktarmak için, Volume olarak aktarma ve Environment Variable olarak aktarma olmak üzere iki yöntem vardır. 
- Her iki yöntem de aşağıdaki YAML dosyasında gösterilmektedir

```
apiVersion: v1
kind: Pod
metadata:
  name: secretpodvolume
spec:
  containers:
  - name: secretcontainer
    image: ozgurozturknet/k8s:blue
    volumeMounts:                   # 2) Oluşturulan secret'lı volume'ü pod'a dahil ediyoruz.
    - name: secret-vol
      mountPath: /secret            # 3) Uygulama içerisinde /secret klasörü volume'e dahil olmuştur.
  volumes:                          # 1) Önce volume'ü oluşturuyoruz ve secret'ı volume'e dahil ediyoruz.
  - name: secret-vol
    secret:
      secretName: mysecret3
---
apiVersion: v1
kind: Pod
metadata:
  name: secretpodenv
spec:
  containers:
  - name: secretcontainer
    image: ozgurozturknet/k8s:blue
    env:                       # Tüm secretları pod içerisinde env. variable olarak tanımlayabiliriz, tüm secretları ve değerlerini tek tek tanımladık.
      - name: username
        valueFrom:
          secretKeyRef:
            name: mysecret3    # mysecret3 isimli secret'ın "db_username" key'li değerini al.
            key: db_username
      - name: password
        valueFrom:
          secretKeyRef:
            name: mysecret3
            key: db_password
      - name: server
        valueFrom:
          secretKeyRef:
            name: mysecret3
            key: db_server
---
apiVersion: v1
kind: Pod
metadata:
  name: secretpodenvall
spec:
  containers:
  - name: secretcontainer
    image: ozgurozturknet/k8s:blue
    envFrom:                 # 2. yöntemle aynı, sadece tek fark tüm secretları tek bir seferde tanımlıyoruz.
    - secretRef:
        name: mysecret3
```

### 18. ConfigMapConfigMap

- Gizli olmayan verileri anahtar/değer eşlenikleri olarak depolamak için kullanılan bir API nesnesidir. 
- Podlar, ConfigMap'i environment variable, komut satırı argümanları veya bir volume olarak bağlanan yapılandırma dosyaları olarak 
  kullanabilir.
- ConfigMap'ler Secret objeleriyle tamamen aynı mantıkta çalışır. 
- Tek farkı; Secret'lar etcd üzerinde base64 ile encoded edilerek encrypted bir şekilde saklanır.
- ConfigMap'ler ise encrypted edilmez ve bu sebeple hassas datalar içermemelidir.

```
kubectl create configmap myconfigmap --from-literal=background=blue --from-file= a.txt
```
- configmap.yaml
```
apiVersion: v1
kind: ConfigMap
metadata:
  name: myconfigmap
data:
  db_server: "db.example.com"    #key:value
  database: "mydatabase"
  site.settings: |               #bir key girilerek birden fazla değer girilebilir.
    color=blue
    padding:25px
---
apiVersion: v1
kind: Pod
metadata:
  name: configmappod
spec:
  containers:
  - name: configmapcontainer
    image: ozgurozturknet/k8s:blue
    env:
      - name: DB_SERVER
        valueFrom:
          configMapKeyRef:
            name: myconfigmap
            key: db_server
      - name: DATABASE
        valueFrom:
          configMapKeyRef:
            name: myconfigmap
            key: database
    volumeMounts:
      - name: config-vol
        mountPath: "/config"
        readOnly: true
  volumes:
    - name: config-vol
      configMap:
        name: myconfigmap
```

config.map

```
{ "name": "Pamuk", 
"surName": "Koza", 
"email": "pamuk@banka.com",
"apiKey": "6bba108d4b2212f2c30c71dfa279e1f77cc5c3b2", 
"text": ["ali", "veli", "on", "yedi", 9, false]}

```

### 19. Node Afinity

- Node affinity kavramsal olarak nodeSelector'a benzer ve nodelara atanan etiketlere göre podunuzun hangi node üstünde schedule edilmeye 
  uygun olduğunu kısıtlamanıza olanak tanır.

podnodeaffinity.yaml
```
apiVersion: v1
kind: Pod
metadata:
  name: nodeaffinitypod1
spec:
  containers:
  - name: nodeaffinity1
    image: ozgurozturknet/k8s
  affinity:                     #tanımla işlemi yapıyoruz
    nodeAffinity: 
      requiredDuringSchedulingIgnoredDuringExecution: #uygun app=blue şeklinde lable sahip worker node bulursan çalışsın
        nodeSelectorTerms:
        - matchExpressions:
          - key: app  #aranan1
            operator: In #In, NotIn, Exists, DoesNotExist 
            values:
            - blue    #aranan2
---
apiVersion: v1
kind: Pod
metadata:
  name: nodeaffinitypod2
spec:
  containers:
  - name: nodeaffinity2
    image: ozgurozturknet/k8s
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution: #uygun app=blue şeklinde lable sahip worker node bul yoksa yine çalış
      - weight: 1
        preference:
          matchExpressions:
          - key: app
            operator: In
            values:
            - blue
      - weight: 2
        preference:
          matchExpressions:
          - key: app
            operator: In
            values:
            - red
---
apiVersion: v1
kind: Pod
metadata:
  name: nodeaffinitypod3
spec:
  containers:
  - name: nodeaffinity3
    image: ozgurozturknet/k8s
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: app
            operator: Exists #In, NotIn, Exists, DoesNotExist
```

```
kubectl apply -f podnodeaffinity.yaml
```

### 20. Pod Affinity
- Pod affinity, podunuzun hangi node üstünde oluşturulmaya uygun olduğunu, nodelardaki etiketlere göre değil,
halihazırda node'da çalışmakta olan podlardaki etiketlere göre sınırlamanıza olanak tanır.

```
apiVersion: v1
kind: Pod
metadata:
  name: frontendpod
  labels:
    app: frontend
    deployment: test
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Pod
metadata:
  name: cachepod
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution: #şart koşulmuş
      - labelSelector:
          matchExpressions:
          - key: app         #şart1
            operator: In
            values:
            - frontend       #şart2
        topologyKey: kubernetes.io/hostname #aynı hostnamede çalışacak
      preferredDuringSchedulingIgnoredDuringExecution: #olsa iyi olur yosa farklı jode çalışsın
      - weight: 1
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: color
              operator: In
              values:
              - blue
          topologyKey: kubernetes.io/hostname
    podAntiAffinity:                                  #İstemediğim şartları belirtiyorum
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: deployment
              operator: In
              values:
              - prod
          topologyKey: topology.kubernetes.io/zone
  containers:
  - name: cachecontainer
    image: redis:6-alpine
```





